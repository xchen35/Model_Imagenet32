{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import optimizers\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_annotations_map():\n",
    "\tvalAnnotationsPath = './resized-tiny-imagenet-200/val/val_annotations.txt'\n",
    "\tvalAnnotationsFile = open(valAnnotationsPath, 'r')\n",
    "\tvalAnnotationsContents = valAnnotationsFile.read()\n",
    "\tvalAnnotations = {}\n",
    "\n",
    "\tfor line in valAnnotationsContents.splitlines():\n",
    "\t\tpieces = line.strip().split()\n",
    "\t\tvalAnnotations[pieces[0]] = pieces[1]\n",
    "\n",
    "\treturn valAnnotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def load_images(path,num_classes):\n",
    "    #Load images\n",
    "    \n",
    "    print('Loading ' + str(num_classes) + ' classes')\n",
    "\n",
    "    X_train=np.zeros([num_classes*500,3,32,32],dtype='uint8')\n",
    "    y_train=np.zeros([num_classes*500], dtype='uint8')\n",
    "\n",
    "    trainPath=path+'/train'\n",
    "\n",
    "    print('loading training images...');\n",
    "\n",
    "    i=0\n",
    "    j=0\n",
    "    annotations={}\n",
    "    for sChild in os.listdir(trainPath):\n",
    "        if sChild == '.DS_Store':\n",
    "            continue\n",
    "        sChildPath = os.path.join(os.path.join(trainPath,sChild),'images')\n",
    "#         print(sChildPath)\n",
    "        annotations[sChild]=j\n",
    "        for c in os.listdir(sChildPath):\n",
    "            if c == '.DS_Store':\n",
    "                continue\n",
    "            X=np.array(Image.open(os.path.join(sChildPath,c)))\n",
    "            if len(np.shape(X))==2:\n",
    "                X_train[i]=np.array([X,X,X])\n",
    "            else:\n",
    "                X_train[i]=np.transpose(X,(2,0,1))\n",
    "            y_train[i]=j\n",
    "            i+=1\n",
    "        j+=1\n",
    "        if (j >= num_classes):\n",
    "            break\n",
    "\n",
    "    print('finished loading training images')\n",
    "\n",
    "    val_annotations_map = get_annotations_map()\n",
    "\n",
    "    X_test = np.zeros([num_classes*50,3,32,32],dtype='uint8')\n",
    "    y_test = np.zeros([num_classes*50], dtype='uint8')\n",
    "\n",
    "\n",
    "    print('loading test images...')\n",
    "\n",
    "    i = 0\n",
    "    testPath=path+'/val/images'\n",
    "    for sChild in os.listdir(testPath):\n",
    "        if sChild == '.DS_Store':\n",
    "            continue\n",
    "        if val_annotations_map[sChild] in annotations.keys():\n",
    "            sChildPath = os.path.join(testPath, sChild)\n",
    "            X=np.array(Image.open(sChildPath))\n",
    "            if len(np.shape(X))==2:\n",
    "                X_test[i]=np.array([X,X,X])\n",
    "            else:\n",
    "                X_test[i]=np.transpose(X,(2,0,1))\n",
    "            y_test[i]=annotations[val_annotations_map[sChild]]\n",
    "            i+=1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    X_train = X_train.transpose(0,2,3,1)\n",
    "    X_test = X_test.transpose(0,2,3,1)\n",
    "    print('finished loading test images')\n",
    "\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 200 classes\n",
      "loading training images...\n",
      "finished loading training images\n",
      "loading test images...\n",
      "finished loading test images\n"
     ]
    }
   ],
   "source": [
    "path='./resized-tiny-imagenet-200'\n",
    "x_train,y_train,x_test,y_test=load_images(path,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100000, 32, 32, 3)\n",
      "y_train shape: (100000,)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000,)\n",
      "100000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# print('x_train shape:', x_train.shape)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 1000\n",
    "epochs = 5\n",
    "data_augmentation = True\n",
    "size = 224\n",
    "num_predictions = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# The first convolutional layer filters the 224 × 224 × 3 input image with 96 kernels of size 11 × 11 × 3 with a stride of 4 pixels\n",
    "\n",
    "# model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "model.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# Max pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "\n",
    "# The second convolutional layer takes as input the (response-normalized and pooled) output of the first convolutional layer and filters it with 256 kernels of size 5 × 5 × 48\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "\n",
    "# The third convolutional layer has 384 kernels of size 3 × 3 × 256 connected to the (normalized, pooled) outputs of the second convolutional layer.\n",
    "\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "# The fourth convolutional layer has 384 kernels of size 3 × 3 × 192\n",
    "\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "# The fifth convolutional layer has 256 kernels of size 3 × 3 × 192\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "\n",
    "# The fully-connected layers have 4096 neurons each\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 96)          34944     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 256)         614656    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 25,682,184\n",
      "Trainable params: 25,680,184\n",
      "Non-trainable params: 2,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      " 74688/100000 [=====================>........] - ETA: 21:52 - loss: 6.1715 - acc: 0.0089"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    \n",
    "          batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
